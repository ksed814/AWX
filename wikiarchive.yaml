---
- name: Download and extract Wikipedia archive
  hosts: 192.168.0.162

  vars:
    archive_dir: /home/kurt/wiki

  tasks:
  # Download the index page
    - name: Download index page
      get_url:
        url: "https://dumps.wikimedia.org/backup-index-bydb.html"
        dest: "{{ archive_dir }}/index.html"

    # Extract the link to the latest archive
    - name: Set archive URL
      set_fact:
        archive_url: "{{ lookup('file', archive_dir + '/index.html') | regex_findall('href=\"(enwiki-.*?.bz2)\"') | first }}"

    # Download the archive
    - name: Download archive
      get_url:
        url: "https://dumps.wikimedia.org/{{ archive_url }}"
        dest: "{{ archive_dir }}/{{ archive_url }}"
        mode: "0644"

    # Extract the archive
    - name: Extract archive
      unarchive:
        src: "{{ archive_dir }}/{{ archive_url }}"
        dest: "{{ archive_dir }}"
        remote_src: yes
        extra_opts:
          - "--no-same-owner"

    # Delete old archives and keep only the latest one
    - name: Delete old archives
      file:
        path: "{{ item }}"
        state: absent
      with_fileglob:
        - "{{ archive_dir }}/enwiki-*.bz2"
      when: item != "{{ archive_dir }}/{{ archive_url }}"

    # Display the archive directory contents
    - name: Show archive directory
      command: ls -l "{{ archive_dir }}"
